import org.antlr.runtime.ClassicToken;
import org.antlr.runtime.Token;

import com.google.common.collect.FluentIterable;
import com.google.common.collect.Iterables;

import mclint.transform.TokenStreamFragment;

aspect TokenPrettyPrint {
  private TokenStreamFragment ASTNode.fragment = null;
  public boolean ASTNode.hasTokenStreamFragment() {
    return this.fragment != null;
  }
  public void ASTNode.setTokenStreamFragment(TokenStreamFragment fragment) {
    this.fragment = fragment;
  }

  protected static TokenStreamFragment ASTNode.fragmentFromObject(Object fragment) {
    if (fragment instanceof String) {
      return TokenStreamFragment.fromSingleToken((String) fragment);
    } else {
      return (TokenStreamFragment) fragment;
    }
  }

  protected static TokenStreamFragment ASTNode.concatFragments(Object... objects) {
    TokenStreamFragment result = fragmentFromObject(objects[0]);
    for (int i = 1; i < objects.length; ++i) {
      result = result.spliceBefore(fragmentFromObject(objects[i]));
    }
    return result;
  }

  protected TokenStreamFragment Stmt.wrapFragments(Object... fragments) {
    TokenStreamFragment fragment = concatFragments(fragments);
    if (isOutputSuppressed()) {
      return concatFragments(getIndent(), fragment, ";");
    } else {
      return concatFragments(getIndent(), fragment);
    }
  }

  protected static <T extends ASTNode<?>> TokenStreamFragment ASTNode.joinTokens(String delimiter, Iterable<T> nodes) {
    FluentIterable<T> fragments = FluentIterable.from(nodes);
    if (fragments.isEmpty()) {
      return TokenStreamFragment.fromSingleToken("");
    }
    TokenStreamFragment result = Iterables.getFirst(nodes, null).tokenize();
    for (T node : Iterables.skip(nodes, 1)) {
      result = result.spliceBefore(delimiter).spliceBefore(node.tokenize());
    }
    if (delimiter.equals("\n")) {
      result = result.spliceBefore("\n");
    }
    return result;
  }

  public TokenStreamFragment ASTNode.tokenize() {
    if (fragment == null) {
      fragment = doTokenize();
    }
    return fragment;
  }

  syn TokenStreamFragment ASTNode.doTokenize() {
    throw new UnsupportedOperationException(getClass().getSimpleName() + "#doTokenize");
  }

  eq Script.doTokenize() = joinTokens("\n", getStmts());
  eq FunctionList.doTokenize() = joinTokens("\n", getFunctions());
  eq Function.doTokenize() = concatFragments(
    getIndent(), "function [", joinTokens(", ", getOutputParams()), "] = ",
    getName().tokenize(), "(", joinTokens(", ", getInputParams()), ")", "\n",
    joinTokens("\n", getStmts()), joinTokens("\n", getNestedFunctions()), "end");

  eq EmptyStmt.doTokenize() = concatFragments("");
  eq ExprStmt.doTokenize() = wrapFragments(getExpr().tokenize());
  eq AssignStmt.doTokenize() = wrapFragments(getLHS().tokenize(), " = ", getRHS().tokenize());
  eq GlobalStmt.doTokenize() = wrapFragments("global", " ", joinTokens(" ", getNames()));
  eq PersistentStmt.doTokenize() = wrapFragments("persistent", " ", joinTokens(" ", getNames()));
  eq ShellCommandStmt.doTokenize() = wrapFragments("!", getCommand());
  eq BreakStmt.doTokenize() = wrapFragments("break");
  eq ContinueStmt.doTokenize() = wrapFragments("continue");
  eq ReturnStmt.doTokenize() = wrapFragments("return");
  eq ForStmt.doTokenize() = concatFragments(
    getIndent(), isParfor() ? "parfor" : "for", " ", getAssignStmt().tokenize(), "\n", joinTokens("\n", getStmts()), "end");
  eq WhileStmt.doTokenize() = concatFragments(
    getIndent(), "while", " ", getExpr().tokenize(), "\n", joinTokens("\n", getStmts()), "end");
  eq IfStmt.doTokenize() = concatFragments(
    getIndent(), "if", " ", joinTokens(getIndent() + "elseif ", getIfBlocks()),
    hasElseBlock() ? getElseBlock().tokenize() : "", getIndent(), "end");
  eq IfBlock.doTokenize() = concatFragments(
    getCondition().tokenize(), "\n", joinTokens("\n", getStmts()));
  eq ElseBlock.doTokenize() = concatFragments(
    getIndent(), "else", "\n", joinTokens("\n", getStmts()));
  eq SwitchStmt.doTokenize() = concatFragments(
    getIndent(), "switch", " ", getExpr().doTokenize(), "\n",
    joinTokens("", getSwitchCaseBlocks()),
    hasDefaultCaseBlock() ? getDefaultCaseBlock().tokenize() : "", getIndent());
  eq SwitchCaseBlock.doTokenize() = concatFragments(
    getIndent(), "case", " ", getExpr().tokenize(), "\n",
    joinTokens("\n", getStmts()));
  eq DefaultCaseBlock.doTokenize() = concatFragments(
    getIndent(), "otherwise", " ", joinTokens("\n", getStmts()));
  eq TryStmt.doTokenize() = concatFragments(
    getIndent(), "try", "\n", joinTokens("\n", getTryStmts()),
    getCatchStmts().getNumChild() > 0 ? "catch" : "",
    getCatchStmts().getNumChild() > 0 ? "\n" : "",
    getCatchStmts().getNumChild() > 0 ? joinTokens("\n", getCatchStmts()) : "",
    getIndent(), "end");

  eq RangeExpr.doTokenize() = concatFragments(
    "(", getLower().tokenize(), " : ",
    hasIncr() ? getIncr().tokenize() : "", hasIncr() ? " : " : "",
    getUpper().tokenize(), ")");
  eq ColonExpr.doTokenize() = concatFragments(":");
  eq EndExpr.doTokenize() = concatFragments("end");
  eq Name.doTokenize() = concatFragments(getID());
  eq NameExpr.doTokenize() = getName().tokenize();
  eq DotExpr.doTokenize() = concatFragments(
    getTarget().tokenize(), ".", getField().tokenize());
  eq ParameterizedExpr.doTokenize() = concatFragments(
    getTarget().tokenize(), "(", joinTokens(", ", getArgs()), ")");
  eq CellIndexExpr.doTokenize() = concatFragments(
    getTarget().tokenize(), "{", joinTokens(", ", getArgs()), "}");
  eq MatrixExpr.doTokenize() = concatFragments(
    "[", joinTokens("; ", getRows()), "]");
  eq CellArrayExpr.doTokenize() = concatFragments(
    "{", joinTokens("; ", getRows()), "}");
  eq Row.doTokenize() = joinTokens(", ", getElements());
  eq FunctionHandleExpr.doTokenize() = concatFragments(
    "@", getName().tokenize());
  eq LambdaExpr.doTokenize() = concatFragments(
    "(", "@", "(", joinTokens(", ", getInputParams()), ")", " ",
    getBody().tokenize(), ")");
  eq IntLiteralExpr.doTokenize() = concatFragments(getValue().getText());
  eq FPLiteralExpr.doTokenize() = concatFragments(getValue().getText());
  eq StringLiteralExpr.doTokenize() = concatFragments("'", getValue(), "'");

  eq UMinusExpr.doTokenize() = concatFragments(
    "(", "-", getOperand().tokenize(), ")");
  eq UPlusExpr.doTokenize() = concatFragments(
    "(", "+", getOperand().tokenize(), ")");
  eq NotExpr.doTokenize() = concatFragments(
    "(", "~", getOperand().tokenize(), ")");
  eq MTransposeExpr.doTokenize() = concatFragments(
    "(", getOperand().tokenize(), "'", ")");
  eq ArrayTransposeExpr.doTokenize() = concatFragments(
    "(", getOperand().tokenize(), ".'", ")");

  syn TokenStreamFragment BinaryExpr.tokenize(String op) =
    concatFragments("(", getLHS().tokenize(), " ", op, " ", getRHS().tokenize(), ")");

  eq PlusExpr.doTokenize() = tokenize("+");
  eq MinusExpr.doTokenize() = tokenize("-");
  eq MTimesExpr.doTokenize() = tokenize("*");
  eq MDivExpr.doTokenize() = tokenize("/");
  eq MLDivExpr.doTokenize() = tokenize("\\");
  eq MPowExpr.doTokenize() = tokenize("^");
  eq ETimesExpr.doTokenize() = tokenize(".*");
  eq EDivExpr.doTokenize() = tokenize("./");
  eq ELDivExpr.doTokenize() = tokenize(".\\");
  eq EPowExpr.doTokenize() = tokenize(".^");
  eq AndExpr.doTokenize() = tokenize("&");
  eq OrExpr.doTokenize() = tokenize("|");
  eq ShortCircuitAndExpr.doTokenize() = tokenize("&&");
  eq ShortCircuitOrExpr.doTokenize() = tokenize("||");
  eq LTExpr.doTokenize() = tokenize("<");
  eq GTExpr.doTokenize() = tokenize(">");
  eq LEExpr.doTokenize() = tokenize("<=");
  eq GEExpr.doTokenize() = tokenize(">=");
  eq EQExpr.doTokenize() = tokenize("==");
  eq NEExpr.doTokenize() = tokenize("~=");
}
